{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB-pretrainedEmbedding-Tensorflow-Keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "FWE_CjEdaPzV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# IMDB Movie Review Classification Using Pre-Trained Embedding"
      ]
    },
    {
      "metadata": {
        "id": "0X8qYiWAaxNq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Import tensorflow and other dependencies"
      ]
    },
    {
      "metadata": {
        "id": "_ZZ-LKJdZSfX",
        "colab_type": "code",
        "outputId": "05115f24-bdb3-44d0-ef05-3de385dd3eb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import io\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8N9UvGLYadC6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Download gloVe vectors, these **pre-trained** embedding vectors will be used to initialize the embedding layer"
      ]
    },
    {
      "metadata": {
        "id": "FsrlVv9hOKHU",
        "colab_type": "code",
        "outputId": "0213ae32-584c-4c15-c0e6-100def3d9a21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-05 19:57:11--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2019-04-05 19:57:16--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  11.7MB/s    in 87s     \n",
            "\n",
            "2019-04-05 19:58:44 (9.44 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BnvMbdhKannp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Because this is a zip file, we'll have to extract the files first as follows:"
      ]
    },
    {
      "metadata": {
        "id": "glW2KZq-Ofmz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('glove.6B.zip', 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VM6FEIyaa_js",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We'll use the embeddings vectors of dimension 100. We'll read the text file line by line and store the word as key and the embedding vector as it's pair value. This way we'll form our **embedding_index** dictionary."
      ]
    },
    {
      "metadata": {
        "id": "ilBjFjhqIEbT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Example of a line from text file: \n",
        "\n",
        "the -0.038194 -0.24487 0.72812 -0.39961 0.083172 0.043953 -0.39141 0.3344 -0.57545 0.087459 0.28787 -0.06731 0.30906 -0.26384 -0.13231 -0.20757 0.33395 -0.33848 -0.31743 -0.48336 0.1464 -0.37304 0.34577 0.052041 0.44946 -0.46971 0.02628 -0.54155 -0.15518 -0.14107 -0.039722 0.28277 0.14393 0.23464 -0.31021 0.086173 0.20397 0.52624 0.17164 -0.082378 -0.71787 -0.41531 0.20335 -0.12763 0.41367 0.55187 0.57908 -0.33477 -0.36559 -0.54857 -0.062892 0.26584 0.30205 0.99775 -0.80481 -3.0243 0.01254 -0.36942 2.2167 0.72201 -0.24978 0.92136 0.034514 0.46745 1.1079 -0.19358 -0.074575 0.23353 -0.052062 -0.22044 0.057162 -0.15806 -0.30798 -0.41625 0.37972 0.15006 -0.53212 -0.2055 -1.2526 0.071624 0.70565 0.49744 -0.42063 0.26148 -1.538 -0.30223 -0.073438 -0.28312 0.37104 -0.25217 0.016215 -0.017099 -0.38984 0.87424 -0.72569 -0.51058 -0.52028 -0.1459 0.8278 0.27062"
      ]
    },
    {
      "metadata": {
        "id": "523VRYkePo5G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embeddings_index = {}\n",
        "with io.open('glove.6B.100d.txt', encoding='utf8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:],dtype='float32')\n",
        "        embeddings_index[word] = coefs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nN-k7rYfZmN2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Download the imdb dataset using **keras.datasets**"
      ]
    },
    {
      "metadata": {
        "id": "ifTuhlhOZj8y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "imdb = keras.datasets.imdb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0LtWyZrgbb2R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load the imdb dataset using the **load** function. This will return a tuple of numpy arrays in the form **(x_train, y_train), (x_test, y_test)**\n",
        "\n",
        "S it will return two objects. One will be stored as (train_data, train_labels) and the other one will be stored as (test_data, test_labels)"
      ]
    },
    {
      "metadata": {
        "id": "Gm-NCIP4ZvNy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0eea059f-90db-4f18-8aac-041b96217862"
      },
      "cell_type": "code",
      "source": [
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oJHBfIDgbtqG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Both trianing and test sets have 25000 movie reviews each. The data is evenly split between train and test. \n",
        "\n",
        "We'll use 25000 reviews for training and 25000 for testing."
      ]
    },
    {
      "metadata": {
        "id": "w7ERXtdRZ9GA",
        "colab_type": "code",
        "outputId": "1dbd9aac-c59a-429b-8571-08e49267426a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Training entries: {}, Training labels:{}\".format(len(train_data), len(train_labels)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training entries: 25000, Training labels:25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Qayrs-TGcTvk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Each sample/review in the training data is a list of integer values, where each integer represents a word in the vocabulary. \n",
        "\n",
        "The label is eitehr 0 or 1, where 0 is a negative review and 1 is a positive review."
      ]
    },
    {
      "metadata": {
        "id": "ZuYXBN-aaP9e",
        "colab_type": "code",
        "outputId": "1c438497-69a9-470c-d84b-1b6eff30b2f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "print(train_data[0])\n",
        "print(train_labels[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Eqfx13ZpcxKU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The length of different review sis different and so we'll have to **pad** them to make them same length inputs. "
      ]
    },
    {
      "metadata": {
        "id": "pfdBaPW_aUz-",
        "colab_type": "code",
        "outputId": "bf3109aa-4bac-47f7-d7df-92e091eb615a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(train_data[0]), len(train_data[1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(218, 189)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "tcdXHK6ZaiZw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We need a way to convert integres back to words. Imdb dataset in keras comes with a built in function get_word_index() which has word integer pairs stored. We'll write a function that will take a list of integers (a sample review from training data) and return the text form of that review. "
      ]
    },
    {
      "metadata": {
        "id": "8Plk_DOWac9T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "73d47180-f791-4fd0-97bb-9029de0406b4"
      },
      "cell_type": "code",
      "source": [
        "# A dictionary mapping words to an integer index\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "# The first indices are reserved\n",
        "word_index = {k:v+3 for k,v in word_index.items()}\n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2  # unknown\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ji7DzJD1axjt",
        "colab_type": "code",
        "outputId": "c4801ef2-1c5b-428f-9ed6-0a1a1034bc52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "decode_review(train_data[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert redford's is an amazing actor and now the same being director norman's father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for retail and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also congratulations to the two little boy's that played the part's of norman and paul they were just brilliant children are often left out of the praising list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "hbT_kLr3b_IF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
        "                                                        value=word_index[\"<PAD>\"],\n",
        "                                                        padding='post',\n",
        "                                                        maxlen=256)\n",
        "\n",
        "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
        "                                                       value=word_index[\"<PAD>\"],\n",
        "                                                       padding='post',\n",
        "                                                       maxlen=256)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o_1ifLTicob2",
        "colab_type": "code",
        "outputId": "4339fc64-c037-458e-dda5-0721d743bb97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "len(train_data[0]), len(train_data[1])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(256, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "wRaoO0AgcsKW",
        "colab_type": "code",
        "outputId": "86daba31-6580-4fa0-d18b-58291f9645f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "cell_type": "code",
      "source": [
        "print(train_data[0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[    1    14    22    16    43   530   973  1622  1385    65   458  4468\n",
            "    66  3941     4   173    36   256     5    25   100    43   838   112\n",
            "    50   670 22665     9    35   480   284     5   150     4   172   112\n",
            "   167 21631   336   385    39     4   172  4536  1111    17   546    38\n",
            "    13   447     4   192    50    16     6   147  2025    19    14    22\n",
            "     4  1920  4613   469     4    22    71    87    12    16    43   530\n",
            "    38    76    15    13  1247     4    22    17   515    17    12    16\n",
            "   626    18 19193     5    62   386    12     8   316     8   106     5\n",
            "     4  2223  5244    16   480    66  3785    33     4   130    12    16\n",
            "    38   619     5    25   124    51    36   135    48    25  1415    33\n",
            "     6    22    12   215    28    77    52     5    14   407    16    82\n",
            " 10311     8     4   107   117  5952    15   256     4 31050     7  3766\n",
            "     5   723    36    71    43   530   476    26   400   317    46     7\n",
            "     4 12118  1029    13   104    88     4   381    15   297    98    32\n",
            "  2071    56    26   141     6   194  7486    18     4   226    22    21\n",
            "   134   476    26   480     5   144    30  5535    18    51    36    28\n",
            "   224    92    25   104     4   226    65    16    38  1334    88    12\n",
            "    16   283     5    16  4472   113   103    32    15    16  5345    19\n",
            "   178    32     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P98jbWBYQjpN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create a weight matrix for the words in the training doc"
      ]
    },
    {
      "metadata": {
        "id": "e0Wh2yIOQmfq",
        "colab_type": "code",
        "outputId": "2576ed7c-b728-4dbd-ccfa-6147cda6f39e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "vocab_size = 88588\n",
        "\n",
        "print(len(word_index))\n",
        "\n",
        "embeddings_matrix = np.zeros((vocab_size, 100))\n",
        "for word, i in word_index.items():\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embeddings_matrix[i] = embedding_vector"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "88588\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F_uiD7-qJ2z6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define the embedding layer:\n",
        "\n",
        "input as 88588(number of words in vocabulary)\n",
        "\n",
        "output shape as 100 because each embedding will be of dim 100\n",
        "\n",
        "Weights as our pretrained embedding matrix\n",
        "\n",
        "trainable as false, because we are not training this layer"
      ]
    },
    {
      "metadata": {
        "id": "z-RDnQgnX-bJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "e = keras.layers.Embedding(vocab_size, 100, weights=[embeddings_matrix], trainable=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-OCGg8-QKwlP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Define the model structure:**\n",
        "\n",
        "Add an average pooling layer\n",
        "\n",
        "Add a fully connected layer with 100 hidden units\n",
        "\n",
        "Add a fully connected layer with 16 hidden units\n",
        "\n",
        "Add a single hidden unit, this is the output node, we'll use sigmoid activation\n",
        "\n",
        "\n",
        "**Output:**\n",
        "\n",
        "1 - positive review\n",
        "\n",
        "0 - negative review\n"
      ]
    },
    {
      "metadata": {
        "id": "bnXVT_9bcyYx",
        "colab_type": "code",
        "outputId": "dc0be555-1a9d-47f5-93f9-7cb528dd7b39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "cell_type": "code",
      "source": [
        "# input shape is the vocabulary count used for the movie reviews (88588 words)\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(e)\n",
        "model.add(keras.layers.GlobalAveragePooling1D())\n",
        "model.add(keras.layers.Dense(100, activation=tf.nn.relu))\n",
        "model.add(keras.layers.Dense(16, activation=tf.nn.relu))\n",
        "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 100)         8858800   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 16)                1616      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 8,870,533\n",
            "Trainable params: 11,733\n",
            "Non-trainable params: 8,858,800\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wh1bx0rcMqY6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Compile the model:**\n",
        "\n",
        "Define loss as binary_crossentropy\n",
        "\n",
        "Define optimizer as adam\n",
        "\n",
        "Define metrics as accuracy"
      ]
    },
    {
      "metadata": {
        "id": "UUU8r-J-gi_Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss = \"binary_crossentropy\", optimizer=\"adam\", metrics = [\"acc\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vz6kVk9ONJB8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Split train data:**\n",
        "\n",
        "Split train data into train and validation sets"
      ]
    },
    {
      "metadata": {
        "id": "Ir090jEyxn1g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_val = train_data[:10000]\n",
        "partial_x_train = train_data[10000:]\n",
        "\n",
        "y_val = train_labels[:10000]\n",
        "partial_y_train = train_labels[10000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BKYGQiLlNY1w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train the model for **500** epochs with **512** batch size and store the history"
      ]
    },
    {
      "metadata": {
        "id": "cGbeCZmGyn-0",
        "colab_type": "code",
        "outputId": "ebae116c-f3da-4a6b-fa8e-14287cd37371",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 18292
        }
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(partial_x_train, partial_y_train, epochs=500, batch_size=512, validation_data=(x_val,y_val), verbose=1)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15000 samples, validate on 10000 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/500\n",
            "15000/15000 [==============================] - 1s 98us/sample - loss: 0.6805 - acc: 0.6262 - val_loss: 0.6642 - val_acc: 0.6634\n",
            "Epoch 2/500\n",
            "15000/15000 [==============================] - 1s 65us/sample - loss: 0.6496 - acc: 0.6618 - val_loss: 0.6335 - val_acc: 0.6819\n",
            "Epoch 3/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.6147 - acc: 0.6905 - val_loss: 0.6037 - val_acc: 0.6955\n",
            "Epoch 4/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.5859 - acc: 0.7076 - val_loss: 0.5756 - val_acc: 0.7144\n",
            "Epoch 5/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.5577 - acc: 0.7321 - val_loss: 0.5464 - val_acc: 0.7413\n",
            "Epoch 6/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.5376 - acc: 0.7461 - val_loss: 0.5322 - val_acc: 0.7544\n",
            "Epoch 7/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.5224 - acc: 0.7559 - val_loss: 0.5165 - val_acc: 0.7600\n",
            "Epoch 8/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.5113 - acc: 0.7653 - val_loss: 0.5061 - val_acc: 0.7681\n",
            "Epoch 9/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.5031 - acc: 0.7691 - val_loss: 0.5026 - val_acc: 0.7667\n",
            "Epoch 10/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4977 - acc: 0.7691 - val_loss: 0.4930 - val_acc: 0.7740\n",
            "Epoch 11/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4916 - acc: 0.7707 - val_loss: 0.4882 - val_acc: 0.7779\n",
            "Epoch 12/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4859 - acc: 0.7790 - val_loss: 0.4874 - val_acc: 0.7759\n",
            "Epoch 13/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4834 - acc: 0.7794 - val_loss: 0.4926 - val_acc: 0.7693\n",
            "Epoch 14/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4835 - acc: 0.7730 - val_loss: 0.4830 - val_acc: 0.7811\n",
            "Epoch 15/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.4800 - acc: 0.7807 - val_loss: 0.4794 - val_acc: 0.7786\n",
            "Epoch 16/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.4760 - acc: 0.7814 - val_loss: 0.4772 - val_acc: 0.7822\n",
            "Epoch 17/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4745 - acc: 0.7839 - val_loss: 0.4757 - val_acc: 0.7810\n",
            "Epoch 18/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.4732 - acc: 0.7843 - val_loss: 0.4779 - val_acc: 0.7820\n",
            "Epoch 19/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4738 - acc: 0.7826 - val_loss: 0.4765 - val_acc: 0.7800\n",
            "Epoch 20/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.4709 - acc: 0.7843 - val_loss: 0.4735 - val_acc: 0.7827\n",
            "Epoch 21/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.4681 - acc: 0.7881 - val_loss: 0.4715 - val_acc: 0.7834\n",
            "Epoch 22/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.4675 - acc: 0.7867 - val_loss: 0.4733 - val_acc: 0.7823\n",
            "Epoch 23/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.4653 - acc: 0.7897 - val_loss: 0.4719 - val_acc: 0.7831\n",
            "Epoch 24/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.4654 - acc: 0.7872 - val_loss: 0.4688 - val_acc: 0.7858\n",
            "Epoch 25/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4681 - acc: 0.7867 - val_loss: 0.4694 - val_acc: 0.7851\n",
            "Epoch 26/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4636 - acc: 0.7881 - val_loss: 0.4756 - val_acc: 0.7795\n",
            "Epoch 27/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.4618 - acc: 0.7893 - val_loss: 0.4671 - val_acc: 0.7871\n",
            "Epoch 28/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.4617 - acc: 0.7899 - val_loss: 0.4691 - val_acc: 0.7838\n",
            "Epoch 29/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4607 - acc: 0.7908 - val_loss: 0.4656 - val_acc: 0.7847\n",
            "Epoch 30/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4656 - acc: 0.7863 - val_loss: 0.4647 - val_acc: 0.7869\n",
            "Epoch 31/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.4649 - acc: 0.7863 - val_loss: 0.4639 - val_acc: 0.7874\n",
            "Epoch 32/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.4597 - acc: 0.7886 - val_loss: 0.4635 - val_acc: 0.7881\n",
            "Epoch 33/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.4596 - acc: 0.7902 - val_loss: 0.4729 - val_acc: 0.7815\n",
            "Epoch 34/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.4580 - acc: 0.7927 - val_loss: 0.4645 - val_acc: 0.7857\n",
            "Epoch 35/500\n",
            "15000/15000 [==============================] - 1s 67us/sample - loss: 0.4557 - acc: 0.7924 - val_loss: 0.4620 - val_acc: 0.7889\n",
            "Epoch 36/500\n",
            "15000/15000 [==============================] - 1s 68us/sample - loss: 0.4565 - acc: 0.7891 - val_loss: 0.4709 - val_acc: 0.7802\n",
            "Epoch 37/500\n",
            "15000/15000 [==============================] - 1s 69us/sample - loss: 0.4633 - acc: 0.7879 - val_loss: 0.4731 - val_acc: 0.7809\n",
            "Epoch 38/500\n",
            "15000/15000 [==============================] - 1s 68us/sample - loss: 0.4573 - acc: 0.7907 - val_loss: 0.4614 - val_acc: 0.7885\n",
            "Epoch 39/500\n",
            "15000/15000 [==============================] - 1s 69us/sample - loss: 0.4526 - acc: 0.7936 - val_loss: 0.4600 - val_acc: 0.7889\n",
            "Epoch 40/500\n",
            "15000/15000 [==============================] - 1s 68us/sample - loss: 0.4519 - acc: 0.7943 - val_loss: 0.4621 - val_acc: 0.7857\n",
            "Epoch 41/500\n",
            "15000/15000 [==============================] - 1s 68us/sample - loss: 0.4527 - acc: 0.7936 - val_loss: 0.4627 - val_acc: 0.7848\n",
            "Epoch 42/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.4545 - acc: 0.7923 - val_loss: 0.4701 - val_acc: 0.7812\n",
            "Epoch 43/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.4498 - acc: 0.7944 - val_loss: 0.4578 - val_acc: 0.7887\n",
            "Epoch 44/500\n",
            "15000/15000 [==============================] - 1s 65us/sample - loss: 0.4501 - acc: 0.7937 - val_loss: 0.4586 - val_acc: 0.7889\n",
            "Epoch 45/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.4498 - acc: 0.7937 - val_loss: 0.4562 - val_acc: 0.7895\n",
            "Epoch 46/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4488 - acc: 0.7933 - val_loss: 0.4559 - val_acc: 0.7901\n",
            "Epoch 47/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4480 - acc: 0.7955 - val_loss: 0.4552 - val_acc: 0.7915\n",
            "Epoch 48/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.4459 - acc: 0.7962 - val_loss: 0.4556 - val_acc: 0.7903\n",
            "Epoch 49/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.4456 - acc: 0.7965 - val_loss: 0.4549 - val_acc: 0.7919\n",
            "Epoch 50/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.4475 - acc: 0.7937 - val_loss: 0.4578 - val_acc: 0.7870\n",
            "Epoch 51/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.4463 - acc: 0.7955 - val_loss: 0.4539 - val_acc: 0.7906\n",
            "Epoch 52/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4450 - acc: 0.7953 - val_loss: 0.4533 - val_acc: 0.7903\n",
            "Epoch 53/500\n",
            "15000/15000 [==============================] - 1s 65us/sample - loss: 0.4439 - acc: 0.7965 - val_loss: 0.4533 - val_acc: 0.7913\n",
            "Epoch 54/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.4423 - acc: 0.7968 - val_loss: 0.4542 - val_acc: 0.7918\n",
            "Epoch 55/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4445 - acc: 0.7973 - val_loss: 0.4547 - val_acc: 0.7899\n",
            "Epoch 56/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4451 - acc: 0.7954 - val_loss: 0.4540 - val_acc: 0.7896\n",
            "Epoch 57/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4421 - acc: 0.7979 - val_loss: 0.4508 - val_acc: 0.7923\n",
            "Epoch 58/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.4420 - acc: 0.7985 - val_loss: 0.4581 - val_acc: 0.7865\n",
            "Epoch 59/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4405 - acc: 0.7991 - val_loss: 0.4505 - val_acc: 0.7916\n",
            "Epoch 60/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.4397 - acc: 0.7976 - val_loss: 0.4525 - val_acc: 0.7906\n",
            "Epoch 61/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4386 - acc: 0.7983 - val_loss: 0.4519 - val_acc: 0.7926\n",
            "Epoch 62/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4384 - acc: 0.7976 - val_loss: 0.4579 - val_acc: 0.7882\n",
            "Epoch 63/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4394 - acc: 0.7974 - val_loss: 0.4493 - val_acc: 0.7921\n",
            "Epoch 64/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4367 - acc: 0.7993 - val_loss: 0.4511 - val_acc: 0.7922\n",
            "Epoch 65/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4397 - acc: 0.7980 - val_loss: 0.4532 - val_acc: 0.7900\n",
            "Epoch 66/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4445 - acc: 0.7955 - val_loss: 0.4487 - val_acc: 0.7933\n",
            "Epoch 67/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4388 - acc: 0.7974 - val_loss: 0.4484 - val_acc: 0.7920\n",
            "Epoch 68/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4354 - acc: 0.7997 - val_loss: 0.4514 - val_acc: 0.7912\n",
            "Epoch 69/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4366 - acc: 0.7999 - val_loss: 0.4574 - val_acc: 0.7881\n",
            "Epoch 70/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4362 - acc: 0.8001 - val_loss: 0.4516 - val_acc: 0.7896\n",
            "Epoch 71/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4369 - acc: 0.8000 - val_loss: 0.4478 - val_acc: 0.7960\n",
            "Epoch 72/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4335 - acc: 0.8017 - val_loss: 0.4486 - val_acc: 0.7923\n",
            "Epoch 73/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.4346 - acc: 0.7992 - val_loss: 0.4587 - val_acc: 0.7852\n",
            "Epoch 74/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4357 - acc: 0.7997 - val_loss: 0.4468 - val_acc: 0.7937\n",
            "Epoch 75/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4368 - acc: 0.7965 - val_loss: 0.4480 - val_acc: 0.7946\n",
            "Epoch 76/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4373 - acc: 0.8002 - val_loss: 0.4574 - val_acc: 0.7864\n",
            "Epoch 77/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4388 - acc: 0.7964 - val_loss: 0.4490 - val_acc: 0.7911\n",
            "Epoch 78/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4315 - acc: 0.8033 - val_loss: 0.4478 - val_acc: 0.7930\n",
            "Epoch 79/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4328 - acc: 0.8018 - val_loss: 0.4516 - val_acc: 0.7904\n",
            "Epoch 80/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4350 - acc: 0.7976 - val_loss: 0.4564 - val_acc: 0.7867\n",
            "Epoch 81/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4308 - acc: 0.8029 - val_loss: 0.4451 - val_acc: 0.7933\n",
            "Epoch 82/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4293 - acc: 0.8035 - val_loss: 0.4491 - val_acc: 0.7920\n",
            "Epoch 83/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.4294 - acc: 0.8018 - val_loss: 0.4544 - val_acc: 0.7885\n",
            "Epoch 84/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4299 - acc: 0.8021 - val_loss: 0.4485 - val_acc: 0.7916\n",
            "Epoch 85/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4293 - acc: 0.8041 - val_loss: 0.4460 - val_acc: 0.7923\n",
            "Epoch 86/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4283 - acc: 0.8040 - val_loss: 0.4473 - val_acc: 0.7939\n",
            "Epoch 87/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4312 - acc: 0.8005 - val_loss: 0.4484 - val_acc: 0.7913\n",
            "Epoch 88/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4288 - acc: 0.8034 - val_loss: 0.4496 - val_acc: 0.7937\n",
            "Epoch 89/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4275 - acc: 0.8026 - val_loss: 0.4484 - val_acc: 0.7923\n",
            "Epoch 90/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4300 - acc: 0.8022 - val_loss: 0.4451 - val_acc: 0.7931\n",
            "Epoch 91/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4306 - acc: 0.8025 - val_loss: 0.4738 - val_acc: 0.7792\n",
            "Epoch 92/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4369 - acc: 0.7995 - val_loss: 0.4481 - val_acc: 0.7927\n",
            "Epoch 93/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4296 - acc: 0.8013 - val_loss: 0.4438 - val_acc: 0.7940\n",
            "Epoch 94/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4245 - acc: 0.8047 - val_loss: 0.4447 - val_acc: 0.7930\n",
            "Epoch 95/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4311 - acc: 0.8013 - val_loss: 0.4580 - val_acc: 0.7861\n",
            "Epoch 96/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4307 - acc: 0.8024 - val_loss: 0.4443 - val_acc: 0.7934\n",
            "Epoch 97/500\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.4249 - acc: 0.8047 - val_loss: 0.4436 - val_acc: 0.7943\n",
            "Epoch 98/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4272 - acc: 0.8010 - val_loss: 0.4428 - val_acc: 0.7938\n",
            "Epoch 99/500\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.4252 - acc: 0.8041 - val_loss: 0.4435 - val_acc: 0.7943\n",
            "Epoch 100/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4234 - acc: 0.8067 - val_loss: 0.4457 - val_acc: 0.7922\n",
            "Epoch 101/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4225 - acc: 0.8074 - val_loss: 0.4494 - val_acc: 0.7906\n",
            "Epoch 102/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4220 - acc: 0.8070 - val_loss: 0.4533 - val_acc: 0.7906\n",
            "Epoch 103/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4270 - acc: 0.8015 - val_loss: 0.4446 - val_acc: 0.7928\n",
            "Epoch 104/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4254 - acc: 0.8039 - val_loss: 0.4448 - val_acc: 0.7924\n",
            "Epoch 105/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4220 - acc: 0.8065 - val_loss: 0.4544 - val_acc: 0.7891\n",
            "Epoch 106/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4249 - acc: 0.8049 - val_loss: 0.4432 - val_acc: 0.7928\n",
            "Epoch 107/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4200 - acc: 0.8067 - val_loss: 0.4434 - val_acc: 0.7946\n",
            "Epoch 108/500\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.4211 - acc: 0.8062 - val_loss: 0.4433 - val_acc: 0.7943\n",
            "Epoch 109/500\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.4192 - acc: 0.8083 - val_loss: 0.4424 - val_acc: 0.7939\n",
            "Epoch 110/500\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.4195 - acc: 0.8078 - val_loss: 0.4520 - val_acc: 0.7901\n",
            "Epoch 111/500\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.4191 - acc: 0.8071 - val_loss: 0.4431 - val_acc: 0.7934\n",
            "Epoch 112/500\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.4194 - acc: 0.8063 - val_loss: 0.4421 - val_acc: 0.7955\n",
            "Epoch 113/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4194 - acc: 0.8078 - val_loss: 0.4421 - val_acc: 0.7946\n",
            "Epoch 114/500\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.4182 - acc: 0.8081 - val_loss: 0.4427 - val_acc: 0.7951\n",
            "Epoch 115/500\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.4182 - acc: 0.8104 - val_loss: 0.4431 - val_acc: 0.7944\n",
            "Epoch 116/500\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.4193 - acc: 0.8080 - val_loss: 0.4475 - val_acc: 0.7943\n",
            "Epoch 117/500\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.4181 - acc: 0.8099 - val_loss: 0.4519 - val_acc: 0.7878\n",
            "Epoch 118/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4168 - acc: 0.8100 - val_loss: 0.4461 - val_acc: 0.7933\n",
            "Epoch 119/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4161 - acc: 0.8093 - val_loss: 0.4418 - val_acc: 0.7944\n",
            "Epoch 120/500\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.4154 - acc: 0.8087 - val_loss: 0.4529 - val_acc: 0.7893\n",
            "Epoch 121/500\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.4181 - acc: 0.8080 - val_loss: 0.4434 - val_acc: 0.7941\n",
            "Epoch 122/500\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.4177 - acc: 0.8065 - val_loss: 0.4546 - val_acc: 0.7899\n",
            "Epoch 123/500\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.4153 - acc: 0.8079 - val_loss: 0.4426 - val_acc: 0.7946\n",
            "Epoch 124/500\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.4172 - acc: 0.8079 - val_loss: 0.4501 - val_acc: 0.7901\n",
            "Epoch 125/500\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.4186 - acc: 0.8080 - val_loss: 0.4635 - val_acc: 0.7864\n",
            "Epoch 126/500\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.4227 - acc: 0.8025 - val_loss: 0.4527 - val_acc: 0.7907\n",
            "Epoch 127/500\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.4153 - acc: 0.8083 - val_loss: 0.4415 - val_acc: 0.7936\n",
            "Epoch 128/500\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.4120 - acc: 0.8111 - val_loss: 0.4416 - val_acc: 0.7954\n",
            "Epoch 129/500\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.4120 - acc: 0.8127 - val_loss: 0.4425 - val_acc: 0.7951\n",
            "Epoch 130/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.4111 - acc: 0.8121 - val_loss: 0.4428 - val_acc: 0.7931\n",
            "Epoch 131/500\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.4142 - acc: 0.8096 - val_loss: 0.4557 - val_acc: 0.7897\n",
            "Epoch 132/500\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.4155 - acc: 0.8085 - val_loss: 0.4409 - val_acc: 0.7958\n",
            "Epoch 133/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4135 - acc: 0.8113 - val_loss: 0.4420 - val_acc: 0.7951\n",
            "Epoch 134/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4116 - acc: 0.8128 - val_loss: 0.4466 - val_acc: 0.7953\n",
            "Epoch 135/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4112 - acc: 0.8121 - val_loss: 0.4452 - val_acc: 0.7940\n",
            "Epoch 136/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4110 - acc: 0.8104 - val_loss: 0.4418 - val_acc: 0.7957\n",
            "Epoch 137/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4102 - acc: 0.8138 - val_loss: 0.4419 - val_acc: 0.7957\n",
            "Epoch 138/500\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.4089 - acc: 0.8121 - val_loss: 0.4484 - val_acc: 0.7916\n",
            "Epoch 139/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4096 - acc: 0.8129 - val_loss: 0.4449 - val_acc: 0.7954\n",
            "Epoch 140/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4160 - acc: 0.8083 - val_loss: 0.4460 - val_acc: 0.7921\n",
            "Epoch 141/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4134 - acc: 0.8096 - val_loss: 0.4441 - val_acc: 0.7961\n",
            "Epoch 142/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4081 - acc: 0.8126 - val_loss: 0.4427 - val_acc: 0.7932\n",
            "Epoch 143/500\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.4091 - acc: 0.8131 - val_loss: 0.4441 - val_acc: 0.7950\n",
            "Epoch 144/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4089 - acc: 0.8141 - val_loss: 0.4431 - val_acc: 0.7963\n",
            "Epoch 145/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4082 - acc: 0.8153 - val_loss: 0.4449 - val_acc: 0.7970\n",
            "Epoch 146/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4072 - acc: 0.8162 - val_loss: 0.4404 - val_acc: 0.7960\n",
            "Epoch 147/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4075 - acc: 0.8147 - val_loss: 0.4412 - val_acc: 0.7958\n",
            "Epoch 148/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4067 - acc: 0.8138 - val_loss: 0.4411 - val_acc: 0.7964\n",
            "Epoch 149/500\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.4092 - acc: 0.8099 - val_loss: 0.4504 - val_acc: 0.7903\n",
            "Epoch 150/500\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.4089 - acc: 0.8139 - val_loss: 0.4468 - val_acc: 0.7950\n",
            "Epoch 151/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4052 - acc: 0.8173 - val_loss: 0.4416 - val_acc: 0.7961\n",
            "Epoch 152/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4087 - acc: 0.8123 - val_loss: 0.4412 - val_acc: 0.7965\n",
            "Epoch 153/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4067 - acc: 0.8171 - val_loss: 0.4413 - val_acc: 0.7971\n",
            "Epoch 154/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4045 - acc: 0.8157 - val_loss: 0.4413 - val_acc: 0.7956\n",
            "Epoch 155/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4041 - acc: 0.8166 - val_loss: 0.4477 - val_acc: 0.7923\n",
            "Epoch 156/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4063 - acc: 0.8132 - val_loss: 0.4489 - val_acc: 0.7945\n",
            "Epoch 157/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4040 - acc: 0.8170 - val_loss: 0.4411 - val_acc: 0.7970\n",
            "Epoch 158/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4087 - acc: 0.8133 - val_loss: 0.4432 - val_acc: 0.7969\n",
            "Epoch 159/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.4035 - acc: 0.8157 - val_loss: 0.4455 - val_acc: 0.7954\n",
            "Epoch 160/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4087 - acc: 0.8118 - val_loss: 0.4440 - val_acc: 0.7939\n",
            "Epoch 161/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4035 - acc: 0.8166 - val_loss: 0.4429 - val_acc: 0.7973\n",
            "Epoch 162/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.4028 - acc: 0.8167 - val_loss: 0.4415 - val_acc: 0.7965\n",
            "Epoch 163/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4028 - acc: 0.8155 - val_loss: 0.4488 - val_acc: 0.7951\n",
            "Epoch 164/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4004 - acc: 0.8176 - val_loss: 0.4418 - val_acc: 0.7967\n",
            "Epoch 165/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4058 - acc: 0.8145 - val_loss: 0.4453 - val_acc: 0.7963\n",
            "Epoch 166/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4035 - acc: 0.8154 - val_loss: 0.4422 - val_acc: 0.7981\n",
            "Epoch 167/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4023 - acc: 0.8153 - val_loss: 0.4445 - val_acc: 0.7949\n",
            "Epoch 168/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4015 - acc: 0.8147 - val_loss: 0.4550 - val_acc: 0.7913\n",
            "Epoch 169/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4025 - acc: 0.8167 - val_loss: 0.4413 - val_acc: 0.7980\n",
            "Epoch 170/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3987 - acc: 0.8209 - val_loss: 0.4420 - val_acc: 0.7970\n",
            "Epoch 171/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3988 - acc: 0.8179 - val_loss: 0.4428 - val_acc: 0.7979\n",
            "Epoch 172/500\n",
            "15000/15000 [==============================] - 1s 65us/sample - loss: 0.3977 - acc: 0.8197 - val_loss: 0.4424 - val_acc: 0.7964\n",
            "Epoch 173/500\n",
            "15000/15000 [==============================] - 1s 66us/sample - loss: 0.3979 - acc: 0.8203 - val_loss: 0.4457 - val_acc: 0.7931\n",
            "Epoch 174/500\n",
            "15000/15000 [==============================] - 1s 68us/sample - loss: 0.3997 - acc: 0.8164 - val_loss: 0.4439 - val_acc: 0.7960\n",
            "Epoch 175/500\n",
            "15000/15000 [==============================] - 1s 67us/sample - loss: 0.3994 - acc: 0.8192 - val_loss: 0.4450 - val_acc: 0.7944\n",
            "Epoch 176/500\n",
            "15000/15000 [==============================] - 1s 67us/sample - loss: 0.3967 - acc: 0.8209 - val_loss: 0.4462 - val_acc: 0.7961\n",
            "Epoch 177/500\n",
            "15000/15000 [==============================] - 1s 68us/sample - loss: 0.3984 - acc: 0.8175 - val_loss: 0.4447 - val_acc: 0.7962\n",
            "Epoch 178/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3960 - acc: 0.8199 - val_loss: 0.4475 - val_acc: 0.7949\n",
            "Epoch 179/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.4010 - acc: 0.8165 - val_loss: 0.4436 - val_acc: 0.7974\n",
            "Epoch 180/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3950 - acc: 0.8207 - val_loss: 0.4429 - val_acc: 0.7974\n",
            "Epoch 181/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3979 - acc: 0.8203 - val_loss: 0.4416 - val_acc: 0.7963\n",
            "Epoch 182/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3952 - acc: 0.8201 - val_loss: 0.4499 - val_acc: 0.7927\n",
            "Epoch 183/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3970 - acc: 0.8217 - val_loss: 0.4436 - val_acc: 0.7948\n",
            "Epoch 184/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3953 - acc: 0.8212 - val_loss: 0.4454 - val_acc: 0.7973\n",
            "Epoch 185/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3978 - acc: 0.8181 - val_loss: 0.4435 - val_acc: 0.7957\n",
            "Epoch 186/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3932 - acc: 0.8229 - val_loss: 0.4453 - val_acc: 0.7946\n",
            "Epoch 187/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3939 - acc: 0.8213 - val_loss: 0.4446 - val_acc: 0.7979\n",
            "Epoch 188/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3941 - acc: 0.8215 - val_loss: 0.4431 - val_acc: 0.7972\n",
            "Epoch 189/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3921 - acc: 0.8237 - val_loss: 0.4513 - val_acc: 0.7928\n",
            "Epoch 190/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3934 - acc: 0.8212 - val_loss: 0.4441 - val_acc: 0.7943\n",
            "Epoch 191/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3938 - acc: 0.8228 - val_loss: 0.4468 - val_acc: 0.7944\n",
            "Epoch 192/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3950 - acc: 0.8219 - val_loss: 0.4462 - val_acc: 0.7953\n",
            "Epoch 193/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3921 - acc: 0.8225 - val_loss: 0.4460 - val_acc: 0.7960\n",
            "Epoch 194/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3933 - acc: 0.8235 - val_loss: 0.4435 - val_acc: 0.7966\n",
            "Epoch 195/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3954 - acc: 0.8220 - val_loss: 0.4474 - val_acc: 0.7945\n",
            "Epoch 196/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3913 - acc: 0.8233 - val_loss: 0.4440 - val_acc: 0.7959\n",
            "Epoch 197/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3909 - acc: 0.8240 - val_loss: 0.4425 - val_acc: 0.7954\n",
            "Epoch 198/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3902 - acc: 0.8248 - val_loss: 0.4485 - val_acc: 0.7943\n",
            "Epoch 199/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3940 - acc: 0.8210 - val_loss: 0.4642 - val_acc: 0.7827\n",
            "Epoch 200/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3990 - acc: 0.8193 - val_loss: 0.4530 - val_acc: 0.7915\n",
            "Epoch 201/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3919 - acc: 0.8227 - val_loss: 0.4586 - val_acc: 0.7892\n",
            "Epoch 202/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3909 - acc: 0.8243 - val_loss: 0.4449 - val_acc: 0.7962\n",
            "Epoch 203/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3914 - acc: 0.8249 - val_loss: 0.4437 - val_acc: 0.7967\n",
            "Epoch 204/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3902 - acc: 0.8246 - val_loss: 0.4433 - val_acc: 0.7966\n",
            "Epoch 205/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3902 - acc: 0.8249 - val_loss: 0.4470 - val_acc: 0.7937\n",
            "Epoch 206/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3942 - acc: 0.8205 - val_loss: 0.4427 - val_acc: 0.7963\n",
            "Epoch 207/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3925 - acc: 0.8244 - val_loss: 0.4467 - val_acc: 0.7947\n",
            "Epoch 208/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3871 - acc: 0.8261 - val_loss: 0.4447 - val_acc: 0.7973\n",
            "Epoch 209/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3868 - acc: 0.8242 - val_loss: 0.4457 - val_acc: 0.7960\n",
            "Epoch 210/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3857 - acc: 0.8264 - val_loss: 0.4455 - val_acc: 0.7953\n",
            "Epoch 211/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3873 - acc: 0.8249 - val_loss: 0.4506 - val_acc: 0.7940\n",
            "Epoch 212/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3876 - acc: 0.8266 - val_loss: 0.4462 - val_acc: 0.7960\n",
            "Epoch 213/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3885 - acc: 0.8253 - val_loss: 0.4515 - val_acc: 0.7965\n",
            "Epoch 214/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3892 - acc: 0.8232 - val_loss: 0.4455 - val_acc: 0.7939\n",
            "Epoch 215/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3850 - acc: 0.8265 - val_loss: 0.4449 - val_acc: 0.7927\n",
            "Epoch 216/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3870 - acc: 0.8257 - val_loss: 0.4496 - val_acc: 0.7951\n",
            "Epoch 217/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3875 - acc: 0.8247 - val_loss: 0.4442 - val_acc: 0.7969\n",
            "Epoch 218/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3852 - acc: 0.8270 - val_loss: 0.4552 - val_acc: 0.7896\n",
            "Epoch 219/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3916 - acc: 0.8211 - val_loss: 0.4540 - val_acc: 0.7909\n",
            "Epoch 220/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3878 - acc: 0.8227 - val_loss: 0.4455 - val_acc: 0.7974\n",
            "Epoch 221/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3844 - acc: 0.8277 - val_loss: 0.4502 - val_acc: 0.7951\n",
            "Epoch 222/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3844 - acc: 0.8256 - val_loss: 0.4533 - val_acc: 0.7904\n",
            "Epoch 223/500\n",
            "15000/15000 [==============================] - 1s 60us/sample - loss: 0.3882 - acc: 0.8267 - val_loss: 0.4465 - val_acc: 0.7950\n",
            "Epoch 224/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3818 - acc: 0.8288 - val_loss: 0.4481 - val_acc: 0.7963\n",
            "Epoch 225/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3854 - acc: 0.8273 - val_loss: 0.4473 - val_acc: 0.7949\n",
            "Epoch 226/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3844 - acc: 0.8271 - val_loss: 0.4476 - val_acc: 0.7957\n",
            "Epoch 227/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3811 - acc: 0.8302 - val_loss: 0.4467 - val_acc: 0.7934\n",
            "Epoch 228/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3846 - acc: 0.8290 - val_loss: 0.4513 - val_acc: 0.7940\n",
            "Epoch 229/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3844 - acc: 0.8275 - val_loss: 0.4490 - val_acc: 0.7961\n",
            "Epoch 230/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.3823 - acc: 0.8265 - val_loss: 0.4551 - val_acc: 0.7933\n",
            "Epoch 231/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3832 - acc: 0.8274 - val_loss: 0.4512 - val_acc: 0.7943\n",
            "Epoch 232/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3803 - acc: 0.8302 - val_loss: 0.4542 - val_acc: 0.7915\n",
            "Epoch 233/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3836 - acc: 0.8280 - val_loss: 0.4491 - val_acc: 0.7908\n",
            "Epoch 234/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3812 - acc: 0.8281 - val_loss: 0.4545 - val_acc: 0.7925\n",
            "Epoch 235/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3795 - acc: 0.8287 - val_loss: 0.4475 - val_acc: 0.7952\n",
            "Epoch 236/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3810 - acc: 0.8289 - val_loss: 0.4564 - val_acc: 0.7910\n",
            "Epoch 237/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3826 - acc: 0.8287 - val_loss: 0.4515 - val_acc: 0.7916\n",
            "Epoch 238/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3790 - acc: 0.8292 - val_loss: 0.4531 - val_acc: 0.7922\n",
            "Epoch 239/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3797 - acc: 0.8294 - val_loss: 0.4507 - val_acc: 0.7917\n",
            "Epoch 240/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3806 - acc: 0.8285 - val_loss: 0.4525 - val_acc: 0.7961\n",
            "Epoch 241/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3776 - acc: 0.8307 - val_loss: 0.4491 - val_acc: 0.7937\n",
            "Epoch 242/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3784 - acc: 0.8301 - val_loss: 0.4645 - val_acc: 0.7851\n",
            "Epoch 243/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3802 - acc: 0.8285 - val_loss: 0.4494 - val_acc: 0.7956\n",
            "Epoch 244/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3799 - acc: 0.8280 - val_loss: 0.4553 - val_acc: 0.7925\n",
            "Epoch 245/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3807 - acc: 0.8285 - val_loss: 0.4525 - val_acc: 0.7943\n",
            "Epoch 246/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3802 - acc: 0.8279 - val_loss: 0.4489 - val_acc: 0.7935\n",
            "Epoch 247/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3786 - acc: 0.8286 - val_loss: 0.4515 - val_acc: 0.7921\n",
            "Epoch 248/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3777 - acc: 0.8313 - val_loss: 0.4510 - val_acc: 0.7913\n",
            "Epoch 249/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3795 - acc: 0.8310 - val_loss: 0.4562 - val_acc: 0.7909\n",
            "Epoch 250/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3770 - acc: 0.8301 - val_loss: 0.4510 - val_acc: 0.7962\n",
            "Epoch 251/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3761 - acc: 0.8313 - val_loss: 0.4501 - val_acc: 0.7933\n",
            "Epoch 252/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3789 - acc: 0.8293 - val_loss: 0.4526 - val_acc: 0.7920\n",
            "Epoch 253/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3773 - acc: 0.8290 - val_loss: 0.4525 - val_acc: 0.7900\n",
            "Epoch 254/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3813 - acc: 0.8271 - val_loss: 0.4549 - val_acc: 0.7903\n",
            "Epoch 255/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3790 - acc: 0.8273 - val_loss: 0.4763 - val_acc: 0.7848\n",
            "Epoch 256/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3768 - acc: 0.8299 - val_loss: 0.4503 - val_acc: 0.7933\n",
            "Epoch 257/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3745 - acc: 0.8323 - val_loss: 0.4513 - val_acc: 0.7942\n",
            "Epoch 258/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3735 - acc: 0.8309 - val_loss: 0.4536 - val_acc: 0.7923\n",
            "Epoch 259/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3751 - acc: 0.8322 - val_loss: 0.4504 - val_acc: 0.7943\n",
            "Epoch 260/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3727 - acc: 0.8331 - val_loss: 0.4585 - val_acc: 0.7910\n",
            "Epoch 261/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3749 - acc: 0.8318 - val_loss: 0.4565 - val_acc: 0.7885\n",
            "Epoch 262/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3730 - acc: 0.8337 - val_loss: 0.4509 - val_acc: 0.7941\n",
            "Epoch 263/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3724 - acc: 0.8330 - val_loss: 0.4522 - val_acc: 0.7933\n",
            "Epoch 264/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3735 - acc: 0.8337 - val_loss: 0.4591 - val_acc: 0.7908\n",
            "Epoch 265/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3739 - acc: 0.8319 - val_loss: 0.4549 - val_acc: 0.7968\n",
            "Epoch 266/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3716 - acc: 0.8339 - val_loss: 0.4620 - val_acc: 0.7854\n",
            "Epoch 267/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3727 - acc: 0.8325 - val_loss: 0.4663 - val_acc: 0.7839\n",
            "Epoch 268/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3758 - acc: 0.8309 - val_loss: 0.4559 - val_acc: 0.7895\n",
            "Epoch 269/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3777 - acc: 0.8284 - val_loss: 0.4510 - val_acc: 0.7927\n",
            "Epoch 270/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3732 - acc: 0.8328 - val_loss: 0.4535 - val_acc: 0.7912\n",
            "Epoch 271/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3709 - acc: 0.8337 - val_loss: 0.4844 - val_acc: 0.7825\n",
            "Epoch 272/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.3742 - acc: 0.8306 - val_loss: 0.4525 - val_acc: 0.7929\n",
            "Epoch 273/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.3732 - acc: 0.8322 - val_loss: 0.4539 - val_acc: 0.7923\n",
            "Epoch 274/500\n",
            "15000/15000 [==============================] - 1s 65us/sample - loss: 0.3719 - acc: 0.8335 - val_loss: 0.4568 - val_acc: 0.7910\n",
            "Epoch 275/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.3744 - acc: 0.8315 - val_loss: 0.4529 - val_acc: 0.7921\n",
            "Epoch 276/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.3701 - acc: 0.8333 - val_loss: 0.4559 - val_acc: 0.7923\n",
            "Epoch 277/500\n",
            "15000/15000 [==============================] - 1s 65us/sample - loss: 0.3743 - acc: 0.8311 - val_loss: 0.4556 - val_acc: 0.7912\n",
            "Epoch 278/500\n",
            "15000/15000 [==============================] - 1s 65us/sample - loss: 0.3705 - acc: 0.8337 - val_loss: 0.4526 - val_acc: 0.7921\n",
            "Epoch 279/500\n",
            "15000/15000 [==============================] - 1s 65us/sample - loss: 0.3710 - acc: 0.8346 - val_loss: 0.4630 - val_acc: 0.7870\n",
            "Epoch 280/500\n",
            "15000/15000 [==============================] - 1s 65us/sample - loss: 0.3726 - acc: 0.8331 - val_loss: 0.4541 - val_acc: 0.7937\n",
            "Epoch 281/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3673 - acc: 0.8358 - val_loss: 0.4666 - val_acc: 0.7877\n",
            "Epoch 282/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3730 - acc: 0.8322 - val_loss: 0.4593 - val_acc: 0.7910\n",
            "Epoch 283/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3675 - acc: 0.8374 - val_loss: 0.4613 - val_acc: 0.7896\n",
            "Epoch 284/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3814 - acc: 0.8263 - val_loss: 0.4604 - val_acc: 0.7894\n",
            "Epoch 285/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3792 - acc: 0.8300 - val_loss: 0.4661 - val_acc: 0.7867\n",
            "Epoch 286/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3729 - acc: 0.8319 - val_loss: 0.4550 - val_acc: 0.7903\n",
            "Epoch 287/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.3656 - acc: 0.8367 - val_loss: 0.4546 - val_acc: 0.7940\n",
            "Epoch 288/500\n",
            "15000/15000 [==============================] - 1s 65us/sample - loss: 0.3645 - acc: 0.8374 - val_loss: 0.4603 - val_acc: 0.7901\n",
            "Epoch 289/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3673 - acc: 0.8361 - val_loss: 0.4563 - val_acc: 0.7926\n",
            "Epoch 290/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3657 - acc: 0.8368 - val_loss: 0.4690 - val_acc: 0.7863\n",
            "Epoch 291/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3688 - acc: 0.8337 - val_loss: 0.4594 - val_acc: 0.7916\n",
            "Epoch 292/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3651 - acc: 0.8352 - val_loss: 0.4578 - val_acc: 0.7912\n",
            "Epoch 293/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3634 - acc: 0.8405 - val_loss: 0.4562 - val_acc: 0.7939\n",
            "Epoch 294/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3678 - acc: 0.8357 - val_loss: 0.4707 - val_acc: 0.7859\n",
            "Epoch 295/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3709 - acc: 0.8321 - val_loss: 0.4545 - val_acc: 0.7907\n",
            "Epoch 296/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3679 - acc: 0.8351 - val_loss: 0.4591 - val_acc: 0.7892\n",
            "Epoch 297/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.3708 - acc: 0.8356 - val_loss: 0.4665 - val_acc: 0.7855\n",
            "Epoch 298/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3743 - acc: 0.8310 - val_loss: 0.4543 - val_acc: 0.7901\n",
            "Epoch 299/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3662 - acc: 0.8363 - val_loss: 0.4642 - val_acc: 0.7879\n",
            "Epoch 300/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3632 - acc: 0.8381 - val_loss: 0.4611 - val_acc: 0.7916\n",
            "Epoch 301/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3689 - acc: 0.8349 - val_loss: 0.4584 - val_acc: 0.7869\n",
            "Epoch 302/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3635 - acc: 0.8353 - val_loss: 0.4595 - val_acc: 0.7878\n",
            "Epoch 303/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3670 - acc: 0.8357 - val_loss: 0.4576 - val_acc: 0.7861\n",
            "Epoch 304/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3638 - acc: 0.8356 - val_loss: 0.4572 - val_acc: 0.7914\n",
            "Epoch 305/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3610 - acc: 0.8406 - val_loss: 0.4579 - val_acc: 0.7886\n",
            "Epoch 306/500\n",
            "15000/15000 [==============================] - 1s 66us/sample - loss: 0.3645 - acc: 0.8363 - val_loss: 0.4586 - val_acc: 0.7898\n",
            "Epoch 307/500\n",
            "15000/15000 [==============================] - 1s 66us/sample - loss: 0.3626 - acc: 0.8385 - val_loss: 0.4599 - val_acc: 0.7896\n",
            "Epoch 308/500\n",
            "15000/15000 [==============================] - 1s 68us/sample - loss: 0.3615 - acc: 0.8404 - val_loss: 0.4633 - val_acc: 0.7907\n",
            "Epoch 309/500\n",
            "15000/15000 [==============================] - 1s 68us/sample - loss: 0.3641 - acc: 0.8353 - val_loss: 0.4599 - val_acc: 0.7925\n",
            "Epoch 310/500\n",
            "15000/15000 [==============================] - 1s 69us/sample - loss: 0.3613 - acc: 0.8400 - val_loss: 0.4613 - val_acc: 0.7902\n",
            "Epoch 311/500\n",
            "15000/15000 [==============================] - 1s 70us/sample - loss: 0.3643 - acc: 0.8388 - val_loss: 0.4666 - val_acc: 0.7874\n",
            "Epoch 312/500\n",
            "15000/15000 [==============================] - 1s 65us/sample - loss: 0.3624 - acc: 0.8380 - val_loss: 0.4655 - val_acc: 0.7935\n",
            "Epoch 313/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3685 - acc: 0.8341 - val_loss: 0.4578 - val_acc: 0.7890\n",
            "Epoch 314/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3669 - acc: 0.8363 - val_loss: 0.4582 - val_acc: 0.7907\n",
            "Epoch 315/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3623 - acc: 0.8390 - val_loss: 0.4696 - val_acc: 0.7849\n",
            "Epoch 316/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3635 - acc: 0.8367 - val_loss: 0.4584 - val_acc: 0.7911\n",
            "Epoch 317/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3598 - acc: 0.8403 - val_loss: 0.4654 - val_acc: 0.7907\n",
            "Epoch 318/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3588 - acc: 0.8404 - val_loss: 0.4623 - val_acc: 0.7888\n",
            "Epoch 319/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3590 - acc: 0.8407 - val_loss: 0.4701 - val_acc: 0.7859\n",
            "Epoch 320/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3591 - acc: 0.8415 - val_loss: 0.4679 - val_acc: 0.7854\n",
            "Epoch 321/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3597 - acc: 0.8384 - val_loss: 0.4630 - val_acc: 0.7897\n",
            "Epoch 322/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3589 - acc: 0.8388 - val_loss: 0.4618 - val_acc: 0.7912\n",
            "Epoch 323/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3616 - acc: 0.8391 - val_loss: 0.4597 - val_acc: 0.7930\n",
            "Epoch 324/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3592 - acc: 0.8383 - val_loss: 0.4645 - val_acc: 0.7884\n",
            "Epoch 325/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3604 - acc: 0.8396 - val_loss: 0.4715 - val_acc: 0.7894\n",
            "Epoch 326/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3630 - acc: 0.8344 - val_loss: 0.4618 - val_acc: 0.7887\n",
            "Epoch 327/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3592 - acc: 0.8401 - val_loss: 0.4619 - val_acc: 0.7893\n",
            "Epoch 328/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3560 - acc: 0.8419 - val_loss: 0.4605 - val_acc: 0.7920\n",
            "Epoch 329/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3588 - acc: 0.8405 - val_loss: 0.4699 - val_acc: 0.7870\n",
            "Epoch 330/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3577 - acc: 0.8421 - val_loss: 0.4652 - val_acc: 0.7897\n",
            "Epoch 331/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3590 - acc: 0.8411 - val_loss: 0.4633 - val_acc: 0.7906\n",
            "Epoch 332/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3550 - acc: 0.8423 - val_loss: 0.4655 - val_acc: 0.7873\n",
            "Epoch 333/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3568 - acc: 0.8400 - val_loss: 0.4636 - val_acc: 0.7906\n",
            "Epoch 334/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3652 - acc: 0.8367 - val_loss: 0.4609 - val_acc: 0.7868\n",
            "Epoch 335/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3584 - acc: 0.8416 - val_loss: 0.4643 - val_acc: 0.7908\n",
            "Epoch 336/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3592 - acc: 0.8381 - val_loss: 0.4648 - val_acc: 0.7890\n",
            "Epoch 337/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3592 - acc: 0.8409 - val_loss: 0.4643 - val_acc: 0.7847\n",
            "Epoch 338/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3602 - acc: 0.8370 - val_loss: 0.4637 - val_acc: 0.7894\n",
            "Epoch 339/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3563 - acc: 0.8435 - val_loss: 0.4711 - val_acc: 0.7855\n",
            "Epoch 340/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3596 - acc: 0.8396 - val_loss: 0.4840 - val_acc: 0.7775\n",
            "Epoch 341/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3580 - acc: 0.8386 - val_loss: 0.4670 - val_acc: 0.7887\n",
            "Epoch 342/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3549 - acc: 0.8409 - val_loss: 0.4646 - val_acc: 0.7857\n",
            "Epoch 343/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3576 - acc: 0.8401 - val_loss: 0.4665 - val_acc: 0.7838\n",
            "Epoch 344/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3544 - acc: 0.8440 - val_loss: 0.4691 - val_acc: 0.7850\n",
            "Epoch 345/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3551 - acc: 0.8416 - val_loss: 0.4666 - val_acc: 0.7895\n",
            "Epoch 346/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3560 - acc: 0.8405 - val_loss: 0.4685 - val_acc: 0.7885\n",
            "Epoch 347/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3541 - acc: 0.8414 - val_loss: 0.4645 - val_acc: 0.7857\n",
            "Epoch 348/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3575 - acc: 0.8395 - val_loss: 0.4639 - val_acc: 0.7892\n",
            "Epoch 349/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3515 - acc: 0.8443 - val_loss: 0.4718 - val_acc: 0.7871\n",
            "Epoch 350/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.3535 - acc: 0.8442 - val_loss: 0.4684 - val_acc: 0.7899\n",
            "Epoch 351/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.3531 - acc: 0.8438 - val_loss: 0.4825 - val_acc: 0.7816\n",
            "Epoch 352/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.3556 - acc: 0.8409 - val_loss: 0.4650 - val_acc: 0.7865\n",
            "Epoch 353/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3499 - acc: 0.8464 - val_loss: 0.4662 - val_acc: 0.7882\n",
            "Epoch 354/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3527 - acc: 0.8426 - val_loss: 0.4932 - val_acc: 0.7765\n",
            "Epoch 355/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3565 - acc: 0.8403 - val_loss: 0.4718 - val_acc: 0.7863\n",
            "Epoch 356/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3546 - acc: 0.8417 - val_loss: 0.4776 - val_acc: 0.7841\n",
            "Epoch 357/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3557 - acc: 0.8422 - val_loss: 0.4747 - val_acc: 0.7836\n",
            "Epoch 358/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3533 - acc: 0.8429 - val_loss: 0.4676 - val_acc: 0.7895\n",
            "Epoch 359/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3510 - acc: 0.8437 - val_loss: 0.4655 - val_acc: 0.7887\n",
            "Epoch 360/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3516 - acc: 0.8457 - val_loss: 0.4651 - val_acc: 0.7888\n",
            "Epoch 361/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3505 - acc: 0.8441 - val_loss: 0.4673 - val_acc: 0.7877\n",
            "Epoch 362/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3511 - acc: 0.8431 - val_loss: 0.4669 - val_acc: 0.7872\n",
            "Epoch 363/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3557 - acc: 0.8423 - val_loss: 0.4677 - val_acc: 0.7862\n",
            "Epoch 364/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3508 - acc: 0.8444 - val_loss: 0.4687 - val_acc: 0.7854\n",
            "Epoch 365/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3489 - acc: 0.8449 - val_loss: 0.4675 - val_acc: 0.7877\n",
            "Epoch 366/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3500 - acc: 0.8447 - val_loss: 0.4703 - val_acc: 0.7873\n",
            "Epoch 367/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3524 - acc: 0.8426 - val_loss: 0.4675 - val_acc: 0.7893\n",
            "Epoch 368/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3539 - acc: 0.8440 - val_loss: 0.4763 - val_acc: 0.7872\n",
            "Epoch 369/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.3536 - acc: 0.8437 - val_loss: 0.4785 - val_acc: 0.7855\n",
            "Epoch 370/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3499 - acc: 0.8457 - val_loss: 0.4756 - val_acc: 0.7816\n",
            "Epoch 371/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3490 - acc: 0.8433 - val_loss: 0.4711 - val_acc: 0.7839\n",
            "Epoch 372/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3549 - acc: 0.8427 - val_loss: 0.4741 - val_acc: 0.7882\n",
            "Epoch 373/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3513 - acc: 0.8451 - val_loss: 0.4818 - val_acc: 0.7827\n",
            "Epoch 374/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3503 - acc: 0.8446 - val_loss: 0.4680 - val_acc: 0.7896\n",
            "Epoch 375/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3470 - acc: 0.8461 - val_loss: 0.4754 - val_acc: 0.7846\n",
            "Epoch 376/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3455 - acc: 0.8478 - val_loss: 0.4719 - val_acc: 0.7888\n",
            "Epoch 377/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3487 - acc: 0.8451 - val_loss: 0.4830 - val_acc: 0.7820\n",
            "Epoch 378/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3520 - acc: 0.8441 - val_loss: 0.4751 - val_acc: 0.7868\n",
            "Epoch 379/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3452 - acc: 0.8471 - val_loss: 0.4695 - val_acc: 0.7866\n",
            "Epoch 380/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3455 - acc: 0.8483 - val_loss: 0.4702 - val_acc: 0.7847\n",
            "Epoch 381/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3455 - acc: 0.8482 - val_loss: 0.4746 - val_acc: 0.7838\n",
            "Epoch 382/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3452 - acc: 0.8484 - val_loss: 0.4784 - val_acc: 0.7819\n",
            "Epoch 383/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3479 - acc: 0.8467 - val_loss: 0.4780 - val_acc: 0.7871\n",
            "Epoch 384/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3466 - acc: 0.8472 - val_loss: 0.4719 - val_acc: 0.7857\n",
            "Epoch 385/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3457 - acc: 0.8471 - val_loss: 0.4746 - val_acc: 0.7835\n",
            "Epoch 386/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3440 - acc: 0.8499 - val_loss: 0.4915 - val_acc: 0.7824\n",
            "Epoch 387/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3451 - acc: 0.8486 - val_loss: 0.4736 - val_acc: 0.7843\n",
            "Epoch 388/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3443 - acc: 0.8470 - val_loss: 0.4793 - val_acc: 0.7842\n",
            "Epoch 389/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3449 - acc: 0.8470 - val_loss: 0.4746 - val_acc: 0.7867\n",
            "Epoch 390/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3440 - acc: 0.8479 - val_loss: 0.4753 - val_acc: 0.7906\n",
            "Epoch 391/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3430 - acc: 0.8497 - val_loss: 0.4759 - val_acc: 0.7845\n",
            "Epoch 392/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3429 - acc: 0.8487 - val_loss: 0.4998 - val_acc: 0.7769\n",
            "Epoch 393/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3478 - acc: 0.8475 - val_loss: 0.4797 - val_acc: 0.7841\n",
            "Epoch 394/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3453 - acc: 0.8491 - val_loss: 0.4792 - val_acc: 0.7827\n",
            "Epoch 395/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3478 - acc: 0.8470 - val_loss: 0.4747 - val_acc: 0.7865\n",
            "Epoch 396/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3432 - acc: 0.8494 - val_loss: 0.4792 - val_acc: 0.7856\n",
            "Epoch 397/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3402 - acc: 0.8518 - val_loss: 0.4777 - val_acc: 0.7891\n",
            "Epoch 398/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3424 - acc: 0.8492 - val_loss: 0.4786 - val_acc: 0.7822\n",
            "Epoch 399/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3433 - acc: 0.8478 - val_loss: 0.4776 - val_acc: 0.7863\n",
            "Epoch 400/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3421 - acc: 0.8494 - val_loss: 0.4753 - val_acc: 0.7854\n",
            "Epoch 401/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3448 - acc: 0.8471 - val_loss: 0.4926 - val_acc: 0.7804\n",
            "Epoch 402/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3396 - acc: 0.8513 - val_loss: 0.4771 - val_acc: 0.7819\n",
            "Epoch 403/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3471 - acc: 0.8460 - val_loss: 0.4763 - val_acc: 0.7826\n",
            "Epoch 404/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3402 - acc: 0.8498 - val_loss: 0.4795 - val_acc: 0.7852\n",
            "Epoch 405/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3417 - acc: 0.8505 - val_loss: 0.4785 - val_acc: 0.7852\n",
            "Epoch 406/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3417 - acc: 0.8512 - val_loss: 0.4778 - val_acc: 0.7818\n",
            "Epoch 407/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3391 - acc: 0.8515 - val_loss: 0.4790 - val_acc: 0.7818\n",
            "Epoch 408/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3424 - acc: 0.8487 - val_loss: 0.4790 - val_acc: 0.7860\n",
            "Epoch 409/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3383 - acc: 0.8519 - val_loss: 0.4771 - val_acc: 0.7863\n",
            "Epoch 410/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3431 - acc: 0.8523 - val_loss: 0.4761 - val_acc: 0.7870\n",
            "Epoch 411/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3421 - acc: 0.8517 - val_loss: 0.4780 - val_acc: 0.7844\n",
            "Epoch 412/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3360 - acc: 0.8546 - val_loss: 0.4764 - val_acc: 0.7878\n",
            "Epoch 413/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3385 - acc: 0.8524 - val_loss: 0.4942 - val_acc: 0.7788\n",
            "Epoch 414/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3381 - acc: 0.8532 - val_loss: 0.4776 - val_acc: 0.7836\n",
            "Epoch 415/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3394 - acc: 0.8513 - val_loss: 0.4822 - val_acc: 0.7858\n",
            "Epoch 416/500\n",
            "15000/15000 [==============================] - 1s 61us/sample - loss: 0.3365 - acc: 0.8539 - val_loss: 0.4909 - val_acc: 0.7827\n",
            "Epoch 417/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.3475 - acc: 0.8443 - val_loss: 0.4900 - val_acc: 0.7833\n",
            "Epoch 418/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3413 - acc: 0.8513 - val_loss: 0.4801 - val_acc: 0.7830\n",
            "Epoch 419/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3356 - acc: 0.8543 - val_loss: 0.4845 - val_acc: 0.7801\n",
            "Epoch 420/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3427 - acc: 0.8488 - val_loss: 0.4849 - val_acc: 0.7807\n",
            "Epoch 421/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3369 - acc: 0.8522 - val_loss: 0.4822 - val_acc: 0.7862\n",
            "Epoch 422/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3404 - acc: 0.8501 - val_loss: 0.4836 - val_acc: 0.7855\n",
            "Epoch 423/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3371 - acc: 0.8519 - val_loss: 0.4896 - val_acc: 0.7770\n",
            "Epoch 424/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3397 - acc: 0.8488 - val_loss: 0.4836 - val_acc: 0.7867\n",
            "Epoch 425/500\n",
            "15000/15000 [==============================] - 1s 66us/sample - loss: 0.3447 - acc: 0.8484 - val_loss: 0.5016 - val_acc: 0.7770\n",
            "Epoch 426/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3504 - acc: 0.8461 - val_loss: 0.4806 - val_acc: 0.7847\n",
            "Epoch 427/500\n",
            "15000/15000 [==============================] - 1s 66us/sample - loss: 0.3394 - acc: 0.8540 - val_loss: 0.4788 - val_acc: 0.7832\n",
            "Epoch 428/500\n",
            "15000/15000 [==============================] - 1s 65us/sample - loss: 0.3369 - acc: 0.8501 - val_loss: 0.4809 - val_acc: 0.7805\n",
            "Epoch 429/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3364 - acc: 0.8505 - val_loss: 0.5033 - val_acc: 0.7804\n",
            "Epoch 430/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3353 - acc: 0.8529 - val_loss: 0.4845 - val_acc: 0.7836\n",
            "Epoch 431/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3371 - acc: 0.8509 - val_loss: 0.4906 - val_acc: 0.7797\n",
            "Epoch 432/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3337 - acc: 0.8520 - val_loss: 0.4853 - val_acc: 0.7835\n",
            "Epoch 433/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.3346 - acc: 0.8531 - val_loss: 0.4852 - val_acc: 0.7867\n",
            "Epoch 434/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3370 - acc: 0.8532 - val_loss: 0.4837 - val_acc: 0.7832\n",
            "Epoch 435/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.3351 - acc: 0.8513 - val_loss: 0.4893 - val_acc: 0.7815\n",
            "Epoch 436/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3354 - acc: 0.8539 - val_loss: 0.4851 - val_acc: 0.7787\n",
            "Epoch 437/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3347 - acc: 0.8549 - val_loss: 0.4881 - val_acc: 0.7834\n",
            "Epoch 438/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3349 - acc: 0.8528 - val_loss: 0.4843 - val_acc: 0.7851\n",
            "Epoch 439/500\n",
            "15000/15000 [==============================] - 1s 66us/sample - loss: 0.3344 - acc: 0.8544 - val_loss: 0.4852 - val_acc: 0.7829\n",
            "Epoch 440/500\n",
            "15000/15000 [==============================] - 1s 67us/sample - loss: 0.3323 - acc: 0.8552 - val_loss: 0.4861 - val_acc: 0.7825\n",
            "Epoch 441/500\n",
            "15000/15000 [==============================] - 1s 68us/sample - loss: 0.3339 - acc: 0.8536 - val_loss: 0.4844 - val_acc: 0.7834\n",
            "Epoch 442/500\n",
            "15000/15000 [==============================] - 1s 69us/sample - loss: 0.3327 - acc: 0.8535 - val_loss: 0.4936 - val_acc: 0.7790\n",
            "Epoch 443/500\n",
            "15000/15000 [==============================] - 1s 70us/sample - loss: 0.3317 - acc: 0.8551 - val_loss: 0.4835 - val_acc: 0.7838\n",
            "Epoch 444/500\n",
            "15000/15000 [==============================] - 1s 70us/sample - loss: 0.3333 - acc: 0.8536 - val_loss: 0.4942 - val_acc: 0.7801\n",
            "Epoch 445/500\n",
            "15000/15000 [==============================] - 1s 70us/sample - loss: 0.3333 - acc: 0.8529 - val_loss: 0.4964 - val_acc: 0.7822\n",
            "Epoch 446/500\n",
            "15000/15000 [==============================] - 1s 69us/sample - loss: 0.3310 - acc: 0.8533 - val_loss: 0.4857 - val_acc: 0.7828\n",
            "Epoch 447/500\n",
            "15000/15000 [==============================] - 1s 67us/sample - loss: 0.3376 - acc: 0.8516 - val_loss: 0.4860 - val_acc: 0.7841\n",
            "Epoch 448/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.3325 - acc: 0.8537 - val_loss: 0.5017 - val_acc: 0.7761\n",
            "Epoch 449/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.3323 - acc: 0.8568 - val_loss: 0.4964 - val_acc: 0.7797\n",
            "Epoch 450/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.3297 - acc: 0.8576 - val_loss: 0.5100 - val_acc: 0.7745\n",
            "Epoch 451/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.3399 - acc: 0.8486 - val_loss: 0.4863 - val_acc: 0.7820\n",
            "Epoch 452/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.3291 - acc: 0.8570 - val_loss: 0.4869 - val_acc: 0.7813\n",
            "Epoch 453/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.3279 - acc: 0.8562 - val_loss: 0.4887 - val_acc: 0.7832\n",
            "Epoch 454/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.3366 - acc: 0.8523 - val_loss: 0.4891 - val_acc: 0.7818\n",
            "Epoch 455/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.3313 - acc: 0.8556 - val_loss: 0.4896 - val_acc: 0.7799\n",
            "Epoch 456/500\n",
            "15000/15000 [==============================] - 1s 65us/sample - loss: 0.3291 - acc: 0.8567 - val_loss: 0.4902 - val_acc: 0.7830\n",
            "Epoch 457/500\n",
            "15000/15000 [==============================] - 1s 67us/sample - loss: 0.3322 - acc: 0.8533 - val_loss: 0.4873 - val_acc: 0.7803\n",
            "Epoch 458/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.3323 - acc: 0.8546 - val_loss: 0.4881 - val_acc: 0.7840\n",
            "Epoch 459/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.3387 - acc: 0.8487 - val_loss: 0.4913 - val_acc: 0.7833\n",
            "Epoch 460/500\n",
            "15000/15000 [==============================] - 1s 67us/sample - loss: 0.3366 - acc: 0.8523 - val_loss: 0.4963 - val_acc: 0.7807\n",
            "Epoch 461/500\n",
            "15000/15000 [==============================] - 1s 67us/sample - loss: 0.3294 - acc: 0.8555 - val_loss: 0.4946 - val_acc: 0.7811\n",
            "Epoch 462/500\n",
            "15000/15000 [==============================] - 1s 68us/sample - loss: 0.3281 - acc: 0.8582 - val_loss: 0.4904 - val_acc: 0.7813\n",
            "Epoch 463/500\n",
            "15000/15000 [==============================] - 1s 65us/sample - loss: 0.3274 - acc: 0.8578 - val_loss: 0.4934 - val_acc: 0.7786\n",
            "Epoch 464/500\n",
            "15000/15000 [==============================] - 1s 65us/sample - loss: 0.3315 - acc: 0.8526 - val_loss: 0.4954 - val_acc: 0.7800\n",
            "Epoch 465/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.3279 - acc: 0.8572 - val_loss: 0.5443 - val_acc: 0.7741\n",
            "Epoch 466/500\n",
            "15000/15000 [==============================] - 1s 65us/sample - loss: 0.3474 - acc: 0.8446 - val_loss: 0.4950 - val_acc: 0.7805\n",
            "Epoch 467/500\n",
            "15000/15000 [==============================] - 1s 66us/sample - loss: 0.3335 - acc: 0.8513 - val_loss: 0.4903 - val_acc: 0.7789\n",
            "Epoch 468/500\n",
            "15000/15000 [==============================] - 1s 67us/sample - loss: 0.3255 - acc: 0.8575 - val_loss: 0.5206 - val_acc: 0.7802\n",
            "Epoch 469/500\n",
            "15000/15000 [==============================] - 1s 67us/sample - loss: 0.3343 - acc: 0.8541 - val_loss: 0.4894 - val_acc: 0.7810\n",
            "Epoch 470/500\n",
            "15000/15000 [==============================] - 1s 65us/sample - loss: 0.3246 - acc: 0.8579 - val_loss: 0.5159 - val_acc: 0.7776\n",
            "Epoch 471/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.3276 - acc: 0.8590 - val_loss: 0.4927 - val_acc: 0.7819\n",
            "Epoch 472/500\n",
            "15000/15000 [==============================] - 1s 66us/sample - loss: 0.3354 - acc: 0.8514 - val_loss: 0.4916 - val_acc: 0.7827\n",
            "Epoch 473/500\n",
            "15000/15000 [==============================] - 1s 66us/sample - loss: 0.3327 - acc: 0.8525 - val_loss: 0.4925 - val_acc: 0.7827\n",
            "Epoch 474/500\n",
            "15000/15000 [==============================] - 1s 66us/sample - loss: 0.3241 - acc: 0.8597 - val_loss: 0.5106 - val_acc: 0.7778\n",
            "Epoch 475/500\n",
            "15000/15000 [==============================] - 1s 67us/sample - loss: 0.3267 - acc: 0.8577 - val_loss: 0.5049 - val_acc: 0.7776\n",
            "Epoch 476/500\n",
            "15000/15000 [==============================] - 1s 66us/sample - loss: 0.3266 - acc: 0.8566 - val_loss: 0.5022 - val_acc: 0.7775\n",
            "Epoch 477/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3314 - acc: 0.8562 - val_loss: 0.4967 - val_acc: 0.7782\n",
            "Epoch 478/500\n",
            "15000/15000 [==============================] - 1s 65us/sample - loss: 0.3243 - acc: 0.8580 - val_loss: 0.4993 - val_acc: 0.7775\n",
            "Epoch 479/500\n",
            "15000/15000 [==============================] - 1s 65us/sample - loss: 0.3291 - acc: 0.8555 - val_loss: 0.4898 - val_acc: 0.7831\n",
            "Epoch 480/500\n",
            "15000/15000 [==============================] - 1s 65us/sample - loss: 0.3252 - acc: 0.8597 - val_loss: 0.4951 - val_acc: 0.7799\n",
            "Epoch 481/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3244 - acc: 0.8587 - val_loss: 0.5025 - val_acc: 0.7813\n",
            "Epoch 482/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3272 - acc: 0.8571 - val_loss: 0.4938 - val_acc: 0.7795\n",
            "Epoch 483/500\n",
            "15000/15000 [==============================] - 1s 65us/sample - loss: 0.3221 - acc: 0.8614 - val_loss: 0.4938 - val_acc: 0.7822\n",
            "Epoch 484/500\n",
            "15000/15000 [==============================] - 1s 65us/sample - loss: 0.3272 - acc: 0.8589 - val_loss: 0.5045 - val_acc: 0.7788\n",
            "Epoch 485/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.3218 - acc: 0.8594 - val_loss: 0.4972 - val_acc: 0.7792\n",
            "Epoch 486/500\n",
            "15000/15000 [==============================] - 1s 66us/sample - loss: 0.3216 - acc: 0.8588 - val_loss: 0.4966 - val_acc: 0.7790\n",
            "Epoch 487/500\n",
            "15000/15000 [==============================] - 1s 67us/sample - loss: 0.3228 - acc: 0.8577 - val_loss: 0.4949 - val_acc: 0.7804\n",
            "Epoch 488/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.3192 - acc: 0.8612 - val_loss: 0.4988 - val_acc: 0.7808\n",
            "Epoch 489/500\n",
            "15000/15000 [==============================] - 1s 65us/sample - loss: 0.3251 - acc: 0.8571 - val_loss: 0.5028 - val_acc: 0.7803\n",
            "Epoch 490/500\n",
            "15000/15000 [==============================] - 1s 65us/sample - loss: 0.3231 - acc: 0.8608 - val_loss: 0.5235 - val_acc: 0.7749\n",
            "Epoch 491/500\n",
            "15000/15000 [==============================] - 1s 65us/sample - loss: 0.3306 - acc: 0.8541 - val_loss: 0.4970 - val_acc: 0.7828\n",
            "Epoch 492/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.3260 - acc: 0.8581 - val_loss: 0.4936 - val_acc: 0.7791\n",
            "Epoch 493/500\n",
            "15000/15000 [==============================] - 1s 65us/sample - loss: 0.3202 - acc: 0.8606 - val_loss: 0.4993 - val_acc: 0.7843\n",
            "Epoch 494/500\n",
            "15000/15000 [==============================] - 1s 65us/sample - loss: 0.3194 - acc: 0.8613 - val_loss: 0.5027 - val_acc: 0.7778\n",
            "Epoch 495/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3227 - acc: 0.8577 - val_loss: 0.5024 - val_acc: 0.7773\n",
            "Epoch 496/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3203 - acc: 0.8605 - val_loss: 0.5031 - val_acc: 0.7761\n",
            "Epoch 497/500\n",
            "15000/15000 [==============================] - 1s 63us/sample - loss: 0.3250 - acc: 0.8568 - val_loss: 0.5017 - val_acc: 0.7788\n",
            "Epoch 498/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.3192 - acc: 0.8623 - val_loss: 0.4973 - val_acc: 0.7804\n",
            "Epoch 499/500\n",
            "15000/15000 [==============================] - 1s 62us/sample - loss: 0.3242 - acc: 0.8612 - val_loss: 0.5007 - val_acc: 0.7812\n",
            "Epoch 500/500\n",
            "15000/15000 [==============================] - 1s 64us/sample - loss: 0.3196 - acc: 0.8583 - val_loss: 0.4998 - val_acc: 0.7789\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9oxvUQhLOg2l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Evaluate the model on test data:**"
      ]
    },
    {
      "metadata": {
        "id": "0xme2JCfzAcD",
        "colab_type": "code",
        "outputId": "c0b70327-d06a-4808-9287-20d8552c8275",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "results = model.evaluate(test_data, test_labels)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 1s 51us/sample - loss: 0.4889 - acc: 0.7828\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0ZhH47Lizp56",
        "colab_type": "code",
        "outputId": "4edf3133-6838-4090-ae84-b99270f6eee7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "print(results)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.4888888516235352, 0.7828]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U-5_UehGzrpw",
        "colab_type": "code",
        "outputId": "f0c53ce4-6522-42e3-e6cd-f82d5fcdc2a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    }
  ]
}